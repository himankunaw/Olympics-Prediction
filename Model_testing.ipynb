{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cleandata\n",
    "import plots\n",
    "import regressor\n",
    "import classifier\n",
    "from sklearn.metrics import mean_squared_error as mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('clean_data2.csv')\n",
    "\n",
    "valid_year = 2012\n",
    "test_year = 2016\n",
    "run_classifier = True\n",
    "run_tuning = True\n",
    "\n",
    "classifier_list = ['LogisticRegression','SVC','GaussianNB','RandomForest','MLP']\n",
    "regressor_list = ['LinearRegression','Ridge','Lasso','SVR','RandomForest']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_classifiers(x_t, y_t, x_v, y_v, run_cv=False):\n",
    "    \n",
    "    clf_predictions = {}\n",
    "    clf_performance = {}\n",
    "    clf_tuned = {}\n",
    "    \n",
    "    for clf_type in classifier_list:\n",
    "        clf = classifier.Classifier(model_type=clf_type)\n",
    "        \n",
    "        if run_cv:\n",
    "            clf.fit_cv(x_t, y_t)\n",
    "            y_predict = np.rint(clf.model_cv.predict(x_v))\n",
    "        \n",
    "        else:\n",
    "            clf.fit(x_t, y_t)\n",
    "            y_predict = np.rint(clf.model_cv.predict(x_v))\n",
    "            \n",
    "        y_predict[y_predict<0] = 0\n",
    "        \n",
    "        clf_performance[clf_type] = score_clf_models(y_predict, clf_type)\n",
    "        clf_predictions[clf_type] = y_predict\n",
    "        \n",
    "        if run_cv:\n",
    "            clf_tuned[clf_type] = clf.model_cv\n",
    "        \n",
    "        else:\n",
    "            clf_tuned[clf_type] = clf.model\n",
    "            \n",
    "        plots.plot_clf(clf_performance)\n",
    "        \n",
    "        return clf_predictions, clf_performance, clf_tuned\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_regressor(x_t, y_t, x_v, y_v, clf_predict=None, run_cv=False):\n",
    "    \n",
    "    y_predict = 99*np.ones(len(y_v))\n",
    "    \n",
    "    if clf_predict is not None:\n",
    "        y_predict[clf_predict==0] = 0\n",
    "        x_t = x_t[y_t>0]\n",
    "        y_t = y_t[y_t>0]\n",
    "        x_v = x_v[clf_predict==1]\n",
    "        y_v = y_v[clf_predict==1]\n",
    "        \n",
    "    reg_performance = {}\n",
    "    reg_tuned = {}\n",
    "    \n",
    "    for reg_type in regressor_list:\n",
    "        reg = regressor.Regressor(model_type=reg_type)\n",
    "        if not run_cv:\n",
    "            reg.fit(x_t, y_t)\n",
    "            yp = np.rint(reg.predict(x_v))\n",
    "            \n",
    "        else:\n",
    "            reg.fit_cv(x_t, y_t)\n",
    "            yp = np.rint(reg.model_cv.predict(x_v))\n",
    "            \n",
    "        yp[yp<0] = 0\n",
    "        \n",
    "        if clf_predict is not None:\n",
    "            y_predict[clf_predict==1] = yp\n",
    "            \n",
    "        else:\n",
    "            y_predict = yp\n",
    "            \n",
    "        plots.plot(y_valid, y_predict, reg_type+'Prediction',\n",
    "                   line=True, save_path='regressorPred.ps')\n",
    "        \n",
    "        reg_performance[reg_type] = score_reg_model(y_predict, reg_type)\n",
    "        \n",
    "        if run_cv:\n",
    "            reg_tuned[reg_type] = reg.model_cv\n",
    "        else:\n",
    "            reg_tuned[reg_type] = reg.model\n",
    "            \n",
    "    if clf_predict is not None:\n",
    "        save_as = 'RegPerformanceWithClassification.ps'\n",
    "    else:\n",
    "        save_as = 'RegPerformanceWithoutClassification.ps'\n",
    "    \n",
    "    plots.plot_reg(reg_performance, save_path = save_as)\n",
    "    \n",
    "    return reg_performance, reg_tuned\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_test_set(x_t, y_t, x_v, y_v, clf=None, reg=None, classify=False):\n",
    "    \n",
    "    clf_predict = np.ones(len(y_v))\n",
    "    yt_bool = np.zeros(len(y_t))\n",
    "    yt_bool[y_t!=0] = 1\n",
    "    \n",
    "    if classify:\n",
    "        clf_predict = clf.fit(x_t, yt_bool).predict(x_v)\n",
    "        \n",
    "    y_predict = 99*np.ones(len(y_v))\n",
    "    \n",
    "    y_predict[clf_predict==0] = 0\n",
    "    x_v = x_v[clf_predict==1]\n",
    "    y_v = y_v[clf_predict==1]\n",
    "\n",
    "    yp = np.rint(reg.fit(x_t, y_t).predict(x_v))\n",
    "            \n",
    "    yp[yp < 0] = 0\n",
    "        \n",
    "    y_predict[clf_predict==1] = yp\n",
    "   \n",
    "    plots.plot(yv, y_predict, 'Final Alg' + ' Predictions',\n",
    "            line=True,save_path='final_prediction.ps')\n",
    "                \n",
    "    test_performance = score_reg_model(y_predict, 'Final Alg')\n",
    "    \n",
    "    return test_performance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_clf_models(y_predict, model):\n",
    "    i=0\n",
    "    nations=[]\n",
    "    yv_print = np.zeros(len(y_valid))\n",
    "    yp_print = np.zeros(len(y_predict))\n",
    "    for index in y_valid.index:\n",
    "        nations.append(data.iloc[index].Nation)\n",
    "        if y_valid[index]>0 : \n",
    "            yv_print[i] =1\n",
    "            yp_print[i]=y_predict[i]\n",
    "            i+=1\n",
    "            \n",
    "    print(model+'Accuracy: ' + str(np.sum(yv_print==yp_print)/len(yv_print)))\n",
    "        \n",
    "    return np.sum(yv_print==yp_print)/len(yv_print)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_reg_model(y_predict, reg_type):\n",
    "    i=0\n",
    "    nations = []\n",
    "    yv_print = np.zeros(len(y_valid))\n",
    "    yp_print = np.zeros(len(y_predict))\n",
    "    for index in y_valid.index:    \n",
    "        nations.append(data.iloc[index].Nation)\n",
    "        yv_print[i] = y_valid[index]\n",
    "        yp_print[i] = y_predict[i]\n",
    "        i += 1\n",
    "    my_df = pd.DataFrame(data={'Nation':nations,'Actual_Medals':yv_print,'Predicted_Medals':yp_print})\n",
    "    print(my_df.sort_values(by=['Actual_Medals'],ascending=False).head(100))\n",
    "    my_df.sort_values(by=['Actual_Medals'],ascending=False).head(100).to_csv('final_alg_predictions.csv',index=False)\n",
    "    top_sorted = my_df.sort_values(by=['Actual_Medals'],ascending=False)[0:100]\n",
    "    print(reg_type + 'Average Std Loss: ' + str(np.sqrt(mse(yv,yp_print))))\n",
    "    print(reg_type + 'Avg Std Loss Top 10: ' + str(np.sqrt(mse(top_sorted['Actual_Medals'], top_sorted['Predicted_Medals']))))\n",
    "    return np.array([np.sqrt(mse(yv,yp_print)),np.sqrt(mse(top_sorted['Actual_Medals'], top_sorted['Predicted_Medals']))]) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dict_argmin(mydict):\n",
    "    if not mydict: \n",
    "        return None\n",
    "    min_val = min(mydict.values())\n",
    "    return [k for k in mydict if mydict[k] == min_val][0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dict_argmax(mydict):\n",
    "    if not mydict: \n",
    "        return None\n",
    "    \n",
    "    max_val = max(mydict.values())\n",
    "    return [k for k in mydict if mydict[k] == max_val][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__': \n",
    "    # Split data into model tuning set (1988-2008) and validation set (2012)    \n",
    "    # For model iteration and selection\n",
    "    trainvalid = cleandata.train_test_split(data,valid_year,normalized=False)\n",
    "    x_train = trainvalid[0]\n",
    "    y_train = trainvalid[1]\n",
    "    x_valid = trainvalid[2]\n",
    "    y_valid = trainvalid[3]\n",
    "    \n",
    "    xt, yt, xv, yv = cleandata.to_numpy(x_train, y_train, x_valid, y_valid)\n",
    "\n",
    "    yt_clf, yv_clf = cleandata.to_clf_data(yt,yv)\n",
    "    \n",
    "    if not run_classifier:\n",
    "        reg_performance, reg_tuned = train_regressor(xt, yt, xv, yv, \n",
    "                                                      clf_predict=None,\n",
    "                                                      run_cv=run_tuning)\n",
    "    else:\n",
    "    \n",
    "        clf_predictions, clf_performance, clf_tuned = train_classifiers(xt, yt_clf, xv, yv_clf, \n",
    "                                                                        run_cv=run_tuning)\n",
    "        \n",
    "        best_classifier = dict_argmax(clf_performance)\n",
    "        \n",
    "        reg_performance, reg_tuned = train_regressor(xt, yt, xv, yv, \n",
    "                                            clf_predict=clf_predictions[best_classifier],\n",
    "                                            run_cv=run_tuning)\n",
    "\n",
    "    reg_scores = {}\n",
    "    for regressor in list(reg_performance.keys()):\n",
    "        score = reg_performance[regressor][0] + 0.25*reg_performance[regressor][1]\n",
    "        reg_scores[regressor] = score\n",
    "                          \n",
    "    best_regressor = dict_argmin(reg_scores)    \n",
    "    \n",
    "    # Split data into final training set (1988-2012) and test set (2016)\n",
    "    # For final predictions    \n",
    "    traintest = cleandata.train_test_split(data, test_year, normalized=False)\n",
    "    x_train = traintest[0]\n",
    "    y_train = traintest[1]\n",
    "    x_test = traintest[2]\n",
    "    y_test = traintest[3]\n",
    "    \n",
    "    xt, yt, xtest, ytest = cleandata.to_numpy(x_train, y_train, x_test, y_test)\n",
    "    \n",
    "    if not run_classifier:\n",
    "        predict_test_set(xt, yt, xtest, ytest, clf=None, reg=reg_tuned[best_regressor], classify=False)\n",
    "    else:\n",
    "        \n",
    "        if 'CV' in str(type(clf_tuned[best_classifier])):\n",
    "            best_clf = clf_tuned[best_classifier].best_estimator_\n",
    "        else:\n",
    "            best_clf = clf_tuned[best_classifier]\n",
    "            \n",
    "        if 'CV' in str(type(reg_tuned[best_regressor])):\n",
    "            best_reg = reg_tuned[best_regressor].best_estimator_\n",
    "        else:\n",
    "            best_reg = reg_tuned[best_regressor]\n",
    "        \n",
    "        predict_test_set(xt, yt, xtest, ytest, clf=best_clf, reg=reg_tuned['Ridge'], classify=True)\n",
    "        \n",
    "        try:\n",
    "            print(reg_tuned[best_regressor].best_estimator_.get_params())\n",
    "        except:\n",
    "            print(reg_tuned[best_regressor].get_params())\n",
    "        try:\n",
    "            print(clf_tuned[best_classifier].best_estimator_.get_params())\n",
    "        except:\n",
    "            print(clf_tuned[best_classifier].get_params())\n",
    "        \n",
    "    # For plotting final results\n",
    "    reg_perf_after = reg_performance\n",
    "    plots.plot_before_after(reg_performance, reg_perf_after)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
