{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import math\n",
    "from features import desired_indicators, field_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge(file1, file2):\n",
    "    data = pd.read_csv(file1)\n",
    "    world = pd.read_csv(file2)\n",
    "    merged = pd.merge(data, world, on='NOC', how='left')\n",
    "    merged.to_csv('merged_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge('athlete_events.csv', 'noc_regions.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data(data, wdi, world, indicators = desired_indicators, field_name = field_names):\n",
    "    #data = pd.read_csv(\"merged_data.csv\")                   \n",
    "    #wdi = pd.read_csv(\"WDIData.csv\")\n",
    "    #world = pd.read_csv(\"noc_regions.csv\")\n",
    "    data = data[data.Season == 'Summer']\n",
    "    data = data.drop(columns=['Height', 'Weight', 'Age', 'Sex', 'Games'])\n",
    "    data.Medal.fillna(False)\n",
    "    \n",
    "    my_cols = ['Nation', 'Year'] + \\\n",
    "        field_name + \\\n",
    "            ['Athletes', 'Athletes_Normalized',\\\n",
    "             'Medals_Last_Games',\\\n",
    "                 'Total_Medals_year',\\\n",
    "                     'Medals']\n",
    "                \n",
    "    # Replace Medal types with True/False\n",
    "    data.Medal.replace('Gold',True, inplace=True)\n",
    "    data.Medal.replace('Silver',True, inplace=True)\n",
    "    data.Medal.replace('Bronze',True, inplace=True)\n",
    "    \n",
    "    # Summing medals for each country and creating new Dataframe\n",
    "    newdf = pd.DataFrame(columns=my_cols)\n",
    "    for region in data.region.unique():\n",
    "        naming_discrpancy = True\n",
    "        if not type(region)==str:\n",
    "            if math.isnan(region):\n",
    "                continue\n",
    "        for year in data.Year.unique():\n",
    "            subset_world = data.loc[(data.Year == year)]\n",
    "            total_medals_year = np.sum(subset_world.Medal)\n",
    "            total_athletes_year = len(subset_world['Name'].unique())\n",
    "            \n",
    "            subset = data.loc[(data.Year == year) & (data.region == region)]\n",
    "            total_medals = np.sum(subset.Medal)\n",
    "            total_athletes = len(subset['Name'].unique())\n",
    "            \n",
    "            total_medals_norm = total_medals / total_medals_year\n",
    "            total_athletes_norm = total_athletes / total_athletes_year\n",
    "            \n",
    "            indicators_list = []\n",
    "            \n",
    "            for i in range(len(indicators)):\n",
    "                ind = indicators[i]\n",
    "                sub = wdi[wdi['Country Name'] == region]\n",
    "                sub = sub[sub['Indicator Code'] == ind]\n",
    "                if len(sub) == 1:\n",
    "                    my_val = sub[str(year)].values\n",
    "                    if len(my_val)>1:\n",
    "                        raise Exception('More than one data point')\n",
    "                    if 'Normalized' in field_names[i]:\n",
    "                        subworld = wdi[wdi['Indicator Code'] == ind]\n",
    "                        world_val = subworld[str(year)].values\n",
    "                        indicators_list.append(my_val[0] / world_val[0])\n",
    "                    else:\n",
    "                        indicators_list.append(my_val[0])\n",
    "                elif len(sub) == 0:\n",
    "                    indicators_list.append(np.nan)\n",
    "                else:\n",
    "                    raise Exception('Indicators list greater than 1')\n",
    "                    \n",
    "                \n",
    "                # Figuring out naming discrepancies\n",
    "                if not np.sum(np.isnan(indicators_list)) == len(indicators_list):\n",
    "                    naming_discrepancy = False\n",
    "                \n",
    "            newdf = newdf.append(pd.DataFrame([[region, year] + indicators_list + \n",
    "                                               [total_athletes, total_athletes_norm, np.nan, total_medals_year, total_medals]], columns = my_cols))\n",
    "        if naming_discrepancy:\n",
    "            print(region)\n",
    "        \n",
    "    unique_years = np.sort(data.Year.unique())\n",
    "    \n",
    "    for i in range(1,len(unique_years)):\n",
    "        this_year = unique_years[i]\n",
    "        last_year = unique_years[i-1]\n",
    "        for nation in newdf[newdf.Year==this_year].Nation.unique():\n",
    "            df_last = newdf.loc[(newdf.Year==last_year) & (newdf.Nation==nation)]\n",
    "            medals_last_year = df_last.Medals.values\n",
    "            if not len(medals_last_year)==1:\n",
    "                raise Exception('Problem with number last year medals')\n",
    "            newdf.loc[(newdf.Year==this_year) & (newdf.Nation==nation), 'Medals_Last_Games'] = medals_last_year[0]\n",
    "    #newdf.to_csv(\"newdata.csv\", index=False)        \n",
    "            \n",
    "    return newdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_data(pd.read_csv(\"merged_data.csv\"), pd.read_csv(\"WDIData.csv\"), pd.read_csv(\"noc_regions.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_duplicate_medals(mgfile):\n",
    "    data = pd.read_csv(mgfile)\n",
    "    tempdf = pd.DataFrame(columns=data.columns)\n",
    "    for year in data.Year.unique():\n",
    "        for event in data[data.Year==year].Event.unique():\n",
    "            for medal in ['Gold','Silver','Bronze']:             \n",
    "                subset = data.loc[(data.Year==year)&(data.Event==event)&(data.Medal==medal)]\n",
    "                if (not subset.empty) and len(subset)>1 and len(subset.Team.unique())==1:\n",
    "                    tempdf = tempdf.append(subset.iloc[1:])\n",
    "                    \n",
    "    return_df = data.drop(tempdf.index)\n",
    "    return_df.to_csv('data_no_duplicate.csv', index=False)\n",
    "    return return_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_duplicate_medals('merged_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(year_begin, year_end, indicators = desired_indicators, field_name = field_names):\n",
    "    merged = pd.read_csv('data_no_duplicate.csv')\n",
    "    regions = pd.read_csv('noc_regions.csv')\n",
    "    wdi = pd.read_csv('WDIData.csv')\n",
    "    \n",
    "    # This variable is included to calculate medals in previous game\n",
    "    year_begin = year_begin-4\n",
    "    merged=merged[merged.Year >= year_begin]\n",
    "    merged=merged[merged.Year <= year_end]\n",
    "    \n",
    "    \n",
    "    world = wdi[wdi['Country Name'] == 'World']\n",
    "    wdi = wdi[wdi['Country Name'].isin(regions.region.unique())]\n",
    "    \n",
    "    wdi = wdi[wdi['Indicator Code'].isin(desired_indicators)]\n",
    "    world = world[world['Indicator Code'].isin(desired_indicators)]\n",
    "    \n",
    "    years_list = [str(i) for i in merged.Year.unique() if (i>=year_begin and i<=year_end)]\n",
    "    temp = wdi[years_list].notna()\n",
    "    wdi = wdi[temp.eq(1).all(axis=1)]\n",
    "    \n",
    "    cleandf = clean_data(merged, wdi, world, desired_indicators, field_names)\n",
    "    \n",
    "    # Getting rid of exampless with NaN values\n",
    "    heatmap = sns.heatmap(cleandf.isnull())\n",
    "    heatmap.set(yticks=[])\n",
    "    heatmap.get_figure().savefig('heatmap.ps', bbox_inches='tight')\n",
    "    cleandf = cleandf.dropna(axis=0)\n",
    "    sns.heatmap(cleandf.isnull())\n",
    "    \n",
    "    cleandf.to_csv('clean_data.csv', index=False)\n",
    "    return cleandf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main(1986,2016)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(data, validation_year, normalized=False):\n",
    "    training_data = data[data.Year<validation_year]\n",
    "    valid_data = data[data.Year == validation_year]\n",
    "    \n",
    "    x_train = training_data.drop(columns=['Nation','Medals'])\n",
    "    y_train = training_data['Medals']\n",
    "    \n",
    "    x_valid = valid_data.drop(columns=['Nation','Medals'])\n",
    "    y_valid = valid_data['Medals']\n",
    "    \n",
    "    return x_train,y_train,x_valid,y_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traintest=train_test_split(pd.read_csv('clean_data.csv'), 2016)\n",
    "traintest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_numpy(x_train, y_train, x_valid, y_valid):\n",
    "    xt = x_train.to_numpy()\n",
    "    yt = y_train.to_numpy()\n",
    "    xv = x_valid.to_numpy()\n",
    "    yv = y_valid.to_numpy()\n",
    "    \n",
    "    return xt,yt,xv,yv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tonumpy = to_numpy(traintest[0], traintest[1], traintest[2], traintest[3])\n",
    "tonumpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_clf_data(yt, yv):\n",
    "    yt_bool = np.zeros(len(yt))\n",
    "    yt_bool[yt!=0] = 1\n",
    "    yv_bool = np.zeros(len(yv))\n",
    "    yv_bool[yv!=0] = 1\n",
    "    \n",
    "    return yt_bool, yv_bool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clfdata=to_clf_data(tonumpy[1], tonumpy[3])\n",
    "clfdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
